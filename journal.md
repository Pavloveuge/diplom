# Журнал

## 02.03.2024

Для начала опишу какие-то текущие мысли.

В моей голове сейчас в первую очередь стоит очевидная (с точки зрения надобности) задача - получить какой-то работающий сетап и сделать это быстро.
Для этого хочется брать какие-то проверенные штуки, которые точно заработают (может не очень хорошо, но заработают).

По сути, у меня три компоненты:
1) Энкодер для звука

Тут есть HuBert-ы, wav2vec-и и прочее, которые учились эмбеддинги сделать и есть просто ASR-модельки.
Можно взять ASR модельку (какой-нибудь конформер опенсорсный), выкинуть из неё декодер и брать выхлопы декодера. Но как-будто это не очень, оно же не училось эмбеды строить.
Поэтому тут я склоняюсь к какому-то не слишком больше предобученному эмбеддеру. Какому конкретно - наверное, пофиг (но так ли это?), главное, чтобы даталика не было
2) VAE/flow-matching

В сетапе бейзлайна тоже хочется взять что-то предобученное.
Тут хочется украсть что-то из текстовых диффузий. Что конкретно - ну, я хз как выбрать.
Вадик предложил потестить текущие текстовые диффузии, с точки зрения скорости генерации, и использовать это как прокси метрику при выборе модели (как показатель сложности модели)
3) Noise predictor

В картинках и TTS видел Unet. В текстовых диффузия трансформеры юзают какие-то.
Но я ничего про noise predictor-ы не знаю. Можно действовать из соображений "как в текстовых диффузиях". Ещё я вот пытаюсь раскурить, а какие они бывают и почему они такие.
Сейчас думаю, что возьму что-то из текстовых диффузий


Ещё есть вопрос про то, какой шум сыпать, но это надо после бейзлайна копать, как-будто, чтобы можно было в математику забуриться и сравнить бейзлайн с чем-то другим хотя бы на уровне заявлений авторов.

Что делал:
- Почитал код diffusers. Вроде туда довольно легко встроиться, просто модельки подсунуть, а трейнлуп и прочий сахар вокруг итак работать будут


Рубрика мыслей вcлух:
- А если ли смысл брать чей-то предобученный, докидывать туда condition на аудио-эмбеды и дообучать?